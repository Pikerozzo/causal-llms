INDICE
 - contesto
 - requisiti
 - alternative esistenti (State of the Art)
 - soluzione sviluppata
 - test
 - conclusioni





CONTEXT:
 advancement in causal inference is crucial, for sound decision-making, reliable AI systems,
potential strong AI and AGI


OBJECTIVE:
 assessment of LLM causal analysis capabilities from text for aiding human efforts,
 focus on causal discovery (finding causal graph)
		(small theory introduction)
 
SOTA:
 from DATA (constraint-based and score-based methods)
 with expert (knwoledge-based)
 LLM-based (metadata-based)


SOLUTION:
 GPT API, prompt eng.
 flow "Data collection -> causal analysis -> graph plotting"
    - Data collection:
          pubmed API, get_ids, get_data, clean_data

    - Causal analysis:
          gpt_NER, gpt_causal_discovery

    - Graph plotting:
          libraries & packages, normalize_edges, cycle_check, plot
 
BENCHMARKS:
 metrics
 benchmark example
 results

DISCUSSION:
 results discussion
 limits

CONCLUSIONS:
 **docs project summary**
 future work




chap 3 - Backgoround
chap 4 - MEthodology And implementation
unire 5 e 6 ?
una ref ha "visitato il" invece che "accessed"
controllare ref per iniziali nomi autori
togliere doi e url
dire che benchmark results sono solo alcune delle metriche (alrte in appendice)
niente wikipedia (es per openAI mettere direttamente sito openAI)
calcolare accuracy benchmarks + riportare risultati (accuracy) di "Can LLMS build causal graphs?", ref #3
dimensioni dei grafi delle benchmark
footnote per referenze che uso solo una volta (spacy, guide)
aggiungere una decina di abstract grafi  (per gli abstract pi√π corti che ci sono) SALVARE ANCHE EXEC_TIME !!




baseline: 	0.20
got3: 		0.61
gpt4: 		0.86





in tabelle, numeri allineati a destra. 2 decimali



RIMETTERE FONT DEL POSTER